{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUDO CAPTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# cap = cv2.VideoCapture(cv2.CAP_DSHOW)\n",
    "cap = cv2.VideoCapture(0)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT-100, 480)\n",
    "mm = 1\n",
    "\n",
    "sudoku = np.zeros((400, 400), np.uint8)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    img = frame[60:-60, :]\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(gray, (15, 15), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 4)\n",
    "    \n",
    "#     kernel = np.ones((15,15), np.float32)/25\n",
    "#     blur = cv2.filter2D(gray, -1, kernel)\n",
    "#     blur = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    canny = cv2.Canny(gray, 50, 100, apertureSize=3)\n",
    "    \n",
    "    using = thresh\n",
    "\n",
    "    using_bgr = cv2.cvtColor(using, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imshow('Before', using_bgr)\n",
    "    lines = cv2.HoughLinesP(using, 1, np.pi/180, 1, minLineLength=2, maxLineGap=5)\n",
    "\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(using_bgr, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        \n",
    "    _, cnts, _ = cv2.findContours(cv2.cvtColor(using_bgr, cv2.COLOR_BGR2GRAY),\n",
    "                                  cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt_max = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "    epsilon = 0.001*cv2.arcLength(cnt_max, True)\n",
    "    approx = cv2.approxPolyDP(cnt_max, epsilon, True)\n",
    "    \n",
    "#     cv2.polylines(using_bgr, approx, False, (255, 255, 255))\n",
    "    \n",
    "#     x, y, w, h = cv2.boundingRect(approx)\n",
    "#     cv2.rectangle(using_bgr, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "    \n",
    "#     mask_value = 255\n",
    "#     fill_color = 0\n",
    "#     stencil = np.zeros(img.shape[:-1]).astype(np.uint8)\n",
    "#     cv2.fillConvexPoly(stencil, approx, mask_value)\n",
    "#     sel = stencil != mask_value # select everything that is not mask_value\n",
    "#     img[sel] = fill_color            # and fill it with fill_color\n",
    "    \n",
    "\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "    cv2.fillConvexPoly(mask, approx, 1)\n",
    "    mask = mask.astype(np.bool)\n",
    "    out = np.zeros_like(img)\n",
    "    out[mask] = img[mask]\n",
    "    cv2.imshow('After', out)\n",
    "    \n",
    "#     cv2.drawContours(using_bgr, c, contourIdx=-1, color=(255, 255, 255),\n",
    "#                      thickness=-1)\n",
    "\n",
    "    n = approx.ravel()\n",
    "    i = 0\n",
    "    x = []\n",
    "    y = []\n",
    "    for j in n:\n",
    "        if(i % 2 == 0):\n",
    "            x.append(n[i])\n",
    "            y.append(n[i + 1])\n",
    "        i = i + 1\n",
    "\n",
    "#     print(len(x))\n",
    "#     print(len(y))\n",
    "    print(np.shape(np.array(cnts)))\n",
    "#     print('--done--')\n",
    "#     pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "#     pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "#     matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "#     result = cv2.warpPerspective(frame, matrix, (500, 600))\n",
    "#     cv2.imshow('Transform', result)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "from numpy.linalg import norm\n",
    "\n",
    "dist = np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[78.18567643756751, 118.33849753989612]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.linalg.norm(np.array(p0)-np.array(p1)), np.linalg.norm(np.array(p2)-np.array(p3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[92.20086767487604, 133.30416347586447]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.linalg.norm(np.array(p0)-np.array(p2)), np.linalg.norm(np.array(p1)-np.array(p3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 640)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<1,-1,-1>,struct cv::Set<3,4,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-78fcd4856e7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m360\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_GRAY2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) c:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.hpp:253: error: (-215:Assertion failed) VScn::contains(scn) && VDcn::contains(dcn) && VDepth::contains(depth) in function 'cv::CvtHelper<struct cv::Set<1,-1,-1>,struct cv::Set<3,4,-1>,struct cv::Set<0,2,5>,2>::CvtHelper'\n"
     ]
    }
   ],
   "source": [
    "num_img = np.ones((360, 640))\n",
    "bgr = cv2.cvtColor(cv2.flip(num_img, 1), cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def two_vector_mag(vector_1, vector_2):\n",
    "    return np.abs(np.linalg.norm(vector_1 - vector_2))\n",
    "\n",
    "\n",
    "def two_vector_ang(vector_1, vector_2):\n",
    "    unit_v1 = vector_1 / np.linalg.norm(vector_1)\n",
    "    unit_v2 = vector_2 / np.linalg.norm(vector_2)\n",
    "    return np.arccos(np.dot(unit_v1, unit_v2))\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX \n",
    "\n",
    "width, height = 640, 360\n",
    "sudo_width, sudo_height = 450, 450\n",
    "sudo = np.zeros((sudo_width, sudo_height, 3))\n",
    "dst = np.array([[0, 0], [sudo_width - 1, 0], [sudo_width - 1, sudo_height - 1], [0, sudo_height - 1]], np.float32)\n",
    "M = cv2.getRotationMatrix2D((sudo_width/2, sudo_height/2), 90, 1.0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = img[60:-60, :]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # ----------------\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "    # ----------------\n",
    "    \n",
    "    _, cnts, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt_max = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    approx = cv2.approxPolyDP(cnt_max, 0.009 * cv2.arcLength(cnt_max, True), True)\n",
    "\n",
    "    try:\n",
    "        p0 = np.array([approx[0][0][0], approx[0][0][1]])\n",
    "        p1 = np.array([approx[1][0][0], approx[1][0][1]])\n",
    "        p2 = np.array([approx[2][0][0], approx[2][0][1]])\n",
    "        p3 = np.array([approx[3][0][0], approx[3][0][1]])            \n",
    "\n",
    "        cv2.circle(img, tuple(p0), 10, (255, 0, 0), -1)\n",
    "        cv2.circle(img, tuple(p1), 10, (0, 0, 255), -1)\n",
    "        cv2.circle(img, tuple(p2), 10, (0, 255, 0), -1)\n",
    "        cv2.circle(img, tuple(p3), 10, (0, 255, 255), -1)\n",
    "                \n",
    "        mag_diff1 = two_vector_mag(p0, p1) - two_vector_mag(p2, p3)\n",
    "        mag_diff2 = two_vector_mag(p0, p2) - two_vector_mag(p1, p3)\n",
    "        ang_diff1 = two_vector_ang(p0, p1) - two_vector_ang(p2, p3)\n",
    "        ang_diff2 = two_vector_ang(p0, p2) - two_vector_ang(p1, p3)\n",
    "        \n",
    "        \n",
    "        if mag_diff1 > 5 or mag_diff2 > 5 or ang_diff1 < 0.5 or ang_diff2 < 0.5:\n",
    "            pass\n",
    "        else:\n",
    "            print('Breaking')\n",
    "            \n",
    "        pts = np.array([approx.tolist()[0][0], approx.tolist()[1][0],\n",
    "                        approx.tolist()[2][0], approx.tolist()[3][0]], np.float32)\n",
    "        \n",
    "        try:\n",
    "            matrix = cv2.getPerspectiveTransform(pts, dst)\n",
    "            sudo = cv2.warpPerspective(img, matrix, (sudo_width, sudo_height))\n",
    "            sudo = cv2.flip(sudo, 1)\n",
    "        \n",
    "            if matrix[0, 2] < 0:\n",
    "                sudo = cv2.warpAffine(sudo, M, (sudo_height, sudo_width))\n",
    "\n",
    "#             if matrix[2, 0]<0 and matrix[0, 2]<0:\n",
    "\n",
    "        except:\n",
    "                pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    cv2.imshow('Sudoku', sudo)\n",
    "    cv2.imshow('Original', img)\n",
    "    cv2.drawContours(thresh, [cnt_max], 0, (255, 255, 255), -1)\n",
    "    cv2.imshow('thresh', thresh)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.48012093e+00,  2.71051468e-02,  7.17391920e+02],\n",
       "       [ 4.11069225e-02,  2.49381997e+00, -1.81500765e+02],\n",
       "       [ 3.11771061e-05,  2.98467567e-05,  1.00000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normal\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.09598489e-01,  2.00886333e+00,  7.86554944e+00],\n",
       "       [ 2.28588349e+00,  5.71470873e-01, -2.78877786e+02],\n",
       "       [ 4.73553376e-04, -3.27360532e-04,  1.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# DIGITIZER - TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sudokus/sudos\\sudo_1.jpg\n",
      "Sudokus/sudos\\sudo_10.jpg\n",
      "Sudokus/sudos\\sudo_12.jpg\n",
      "Sudokus/sudos\\sudo_13.jpg\n",
      "Sudokus/sudos\\sudo_15.jpg\n",
      "Sudokus/sudos\\sudo_2.jpg\n",
      "Sudokus/sudos\\sudo_3.jpg\n",
      "Sudokus/sudos\\sudo_4.jpg\n",
      "Sudokus/sudos\\sudo_6.jpg\n",
      "Sudokus/sudos\\sudo_7.jpg\n",
      "Sudokus/sudos\\sudo_8.jpg\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "files = glob.glob(\"Sudokus/sudos/*.jpg\")\n",
    "# print(files)\n",
    "i = 0\n",
    "\n",
    "for img in files:\n",
    "    sudo = cv2.imread(img)\n",
    "    print(img)\n",
    "    delta_w, delta_h = int(sudo.shape[0] / 9), int(sudo.shape[1] / 9)\n",
    "    for h in range(9):\n",
    "        for w in range(9):\n",
    "            crop = sudo[w*delta_w : (w*delta_w+delta_w), h*delta_h : (h*delta_h+delta_h)]\n",
    "            cv2.imwrite('Sudokus/generated/img_'+str(i)+'.jpg', crop)\n",
    "            i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "def split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    validation_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    validation_set = shuffled_set[-validation_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in validation_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = VALIDATION + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "\n",
    "source_dir = 'dataset/source/'\n",
    "training_dir = 'dataset/training/'\n",
    "validation_dir = 'dataset/validation/'\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    src_dir = source_dir + 'num_' + str(i) + '/'\n",
    "    train_dir = training_dir + 'num_' + str(i) + '/'\n",
    "    valid_dir = validation_dir + 'num_' + str(i) + '/'\n",
    "    split_data(src_dir, train_dir, valid_dir, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dir = source_dir + 'blank/'\n",
    "train_dir = training_dir + 'blank/'\n",
    "valid_dir = validation_dir + 'blank/'\n",
    "split_data(src_dir, train_dir, valid_dir, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8034 images belonging to 10 classes.\n",
      "Found 2001 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = \"dataset/source/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(validation_split=0.2,\n",
    "                                   rescale=1./255)\n",
    "\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                  target_size=(28, 28),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=16,\n",
    "                                                  subset='training')\n",
    "\n",
    "valid_batches = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                  target_size=(28, 28),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=16,\n",
    "                                                  subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9125 images belonging to 10 classes.\n",
      "Found 1008 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "TRAINING_DIR = \"dataset/dataset/training/\"\n",
    "VALIDATION_DIR = \"dataset/dataset/validation/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_batches = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                  target_size=(28, 28),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=32)\n",
    "\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_batches = valid_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                  target_size=(28, 28),\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blank': 0,\n",
       " 'num_1': 1,\n",
       " 'num_2': 2,\n",
       " 'num_3': 3,\n",
       " 'num_4': 4,\n",
       " 'num_5': 5,\n",
       " 'num_6': 6,\n",
       " 'num_7': 7,\n",
       " 'num_8': 8,\n",
       " 'num_9': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per = train_batches.index_array\n",
    "# classes = train_batches.classes[per]\n",
    "# print(classes)\n",
    "# .class_indices\n",
    "# .filenames\n",
    "train_batches.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "\n",
    "class Cally(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):  # a special method in keras.callbacks\n",
    "        if(logs.get('acc') > 0.95):          # termination condition\n",
    "            print('\\nReached 95% Accuracy, terminating!\\n')\n",
    "            self.model.stop_training = True    # terminates the training\n",
    "CB = Cally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 48/285 [====>.........................] - ETA: 1:15 - loss: 2.3480 - acc: 0.1139"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-268afc2ed684>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                               callbacks=[CB])\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# model.save(\"digits_finder_2.h5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_batches,\n",
    "                              steps_per_epoch=train_batches.n//train_batches.batch_size,\n",
    "                              epochs=100,\n",
    "                              validation_data=valid_batches,\n",
    "                              callbacks=[CB])\n",
    "\n",
    "# model.save(\"digits_finder_2.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3737616012800869426\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8767822103192582429\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3186897715\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12635197839882935408\n",
      "physical_device_desc: \"device: 0, name: GeForce 840M, pci bus id: 0000:03:00.0, compute capability: 5.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1021341827538652708\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-237dd3fa35fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAD4CAYAAABbl2n6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUVf7H8fcXAiFAIDQRqaKgFEEwCgrWtaCrgogFO7iurg27IlhXVlh7QcS6LjZcu6uoqLu4ii0g0iwgKkqXDtJzfn98J78ETEiAydyZyef1PPchmblz54zjw4dz7jnfYyEEREREUkmlqBsgIiKyrRReIiKSchReIiKSchReIiKSchReIiKScjKibkBFUb9+/dCiRYuomyEiklImTJjwawihwZaPK7wSpEWLFuTl5UXdDBGRlGJmPxX3uIYNRUQk5Si8REQk5Si8REQk5Si8REQk5Si8REQk5Si8REQk5Si8REQk5Si8kt0DD8BLL8HGjVG3REQkaSi8kll+PqPv+IkJff4Gu+4KQ4bAokVRt0pEJHIKryS2KVTi+ip3kMsE+m74J98PfsJD7OabYeXKqJsnIhIZhVcSq1wZJk40Bg2C11Ycyp4ZMxnQ6AUW3/IAtGwJd98Nq1ZF3UwRkYRTeCW52rXhttvg+++hf3/jwVnHsHv2Au7JuYX1V14HTZvC9dfD/PlRN1VEJGEUXimiUSMYORK++gr22z+DK2ZeSPumy3mz7dUwdCi0aAEXXOApJyKS5hReKaZ9e3jnHXjrLahUPYtjx1/PMQet5Nte18KTT0Lr1nDGGTB3btRNFREpNwqvFHX00TB5Mtx1F3z8ZQ06vHILQy7/lQ2XXQ0vvght2sBDD0F+ftRNFRGJO4VXCqtaFa64Ar77Dnr1gsHDssl9bygTnp8B++4LF10EBxwAn30WdVNFROJK4ZUGGjaE0aPhlVd8GViXPk259cCxbHxyFPz4I3TtCqefDrNnR91UEZG4UHilkV69YPp06NsXbrrZ6DbiDL57ayYMGgQvvwx77gkPPqihRBFJeQqvNJOTA6NGeU9sxgzodGBN/tn6NvjmGzj4YLjkEujRA+bMibqpIiLbTeGVpk4+GaZM8VtfZ58N597anN9efAtGjICPP4a99oI33oi6mSIi20XhlcYaN4b33oMbbvBZ9Pt1Mb499AKYNMnLTB1/vC9wVtFfEUkxCq80l5EBt97qa8MWLPCe2MtTWnnv67zz4Pbb4aijYOHCqJsqIlJmCq8K4ogjYOJEaNsWTjwRrrmxGptGPOJdsvHjITcX8vKibqaISJkovCqQpk1h3Di48EK44w444QRYfdI53gszg+7d4Z//jLqZIiKlUnhVMJmZMHy4H2++CYccAvN36ey9rm7dfHbHZZfpPpiIJDWFVwV14YXw6qu+LqxrV/h2SQO/MXbZZXDffV5/asmSqJspIlIshVcFdtxxPoz4228+Yjhxcgbccw888QR8+CHstx98/XXUzRQR+R2FVwWXmwsffQTVq/sQ4rhxQL9+8N//+kaXBxzgP4uIJBGFl9C6tc/ZaNzYi2+MGQPsvz98+qlvJHbkkV62Q0QkSSi8BIAmTeB///OdVHr18v3CaNHCp9EfeCCcdZavCQsh6qaKiCi8pFD9+l6Ro317n0b/5pt4scQxY7wq/fXXw7XXKsBEJHIKL9lM3boeYHvtBb17x4YQq1b19V8XXeQLxM4/HzZtirqpIlKBKbzkd+rUgbFjvQfWu3dsEkelSvDAA769yqOPQv/+2lpFRCKj8JJi1akDb7/tt72OOy5WOcoMbrsN/vpX74lddpmGEEUkEgovKVGDBj6EWK+e1+6dNi32xKBBcNVV3hO76aZI2ygiFZPCS7aqYFuVzEyfRv/zz3gP7O9/hz/9yXth99wTdTNFpIJReEmpdtvNJ26sWOE9sCVL8AB7+GHo0weuvBJeeSXqZopIBaLwkjLp2BFeew2+/973sFyzBqhc2e99deniU+k//zzqZopIBaHwkjI75BB45hlft3z66bHJhllZnmo77+wzO378MeJWikhFoPCSbdKnD9x9t48SXndd7MGddvIVzevXwzHHwLJlkbZRRNKfwku22YABhRtaPvpo7ME2beDll2HGDE+4DRsibaOIpDeFl2wzM9/yq0cP+MtffDYiAIce6mn2/vv+hNaAiUg5UXjJdsnIgNGjYc894eSTYdas2BPnnAODB8Pjj8OwYVE2UUTSmMJLtlutWr4bcwheRuq332JP3Hor9O0LAwfC009H2kYRSU8KL9khu+8Ozz4LkyfDeefFRgrN4MknfRixXz8vlCgiEkcKL9lhRx/tJQ+ffRbuvTf2YGamT0ls0wZOPBEmTYq0jSKSXhReEhcDB/oeYNdc4xswA1C7tpfmyMnxKfQ//xxpG0UkfSi8JC7M4IknoGlTOOWUWAkp8OKIY8bA6tXwxz96jSkRkR2k8JK4ycnxGYjz5vmtrv+fKd+uHbz4Ikyf7sm2cWOk7RSR1Kfwkrjad19fvPz660XufwEccQSMGOGbhA0YEFn7RCQ9KLwk7i69FHr1gmuv3WKexnnneQX6hx7yeogiItvJgqogJERubm7Iy8uLuhkJs3gxdOjgczby8qB69dgT69dD167wyy8wdarXRRQRKYGZTQgh5G75uHpeUi7q1YN//AO+/hquvrrIE1Wr+jYqy5fDBReohJSIbBeFl5SbI46AK67wUcJ//7vIE+3b+8KwV15RBQ4R2S4aNkyQijZsWGDdOthvP5g/H6ZNg/r1Y09s2uQbhE2eDJ98Am3bRtlMEUlSGjaUSGRmwqhRvu5rs0mGlSv7zpZZWb7+a+HCyNooIqlH4SXlrkMHLzT/7LNbTDJs1gzeeAMWLICePWHNmsjaKCKpReElCTFwoIfYBRcUqb4BvjDs6afhs898OxUNY4tIGSi8JCGqVvXZh4sWwWWXbfFk795w++3wwgvw8MNRNE9EUozCSxKmUyfvgY0aBe+8s8WT11zjWzNfeSV8800k7ROR1KHwkoQaPNh3Xz7/fFi1qsgTBZV9q1eH00/3xcwiIiVQeElCZWbCo4/CTz/BjTdu8WSjRv7kxIlwyy2RtE9EUoPCSxKue3efuHHfffDFF1s8ecIJcO65fg/so48iaZ+IJD8tUk6QirpIuSTLl/u65Pr1vfZhlSpFnly1Cjp2hPx8+OorqFUrsnaKSLS0SFmSSu3aMHy4F9i4//4tnqxZ06fPz56t7VNEpFgKL4lMz55w3HFw002eU5vZf38YNMjn17/0UhTNE5EkpvCSyJjBAw/4uuRiO1g33OCLmP/8Z5gzJ+HtE5HkpfCSSDVv7j2vV1/13Zc3U6WKDx+uXQtnneX3wEREUHhJErj8cmjXDi6+GFav3uLJ1q39ptgHH8Add0TSPhFJPgoviVyVKl4V6uefYciQYk7o3x9OOslXOH/+ecLbJyLJR+ElSaF7dzj7bLjzTvj22y2eNIORI2GXXeC002DlykjaKCLJQ+ElSWPYMK8OdcklxRSXr1PH9/+aNQuuvz6S9olI8lB4SdJo2BBuuw3Gji1hdnz37n5jbPhw+PTThLdPRJKHKmwkiCpslM3GjT47ftEiLy5fs+YWJ6xc6aU5cnK8BuJmpTlEJN2owoakhIwMeOghX9b1t78Vc0J2tve8pk6Fu+5KePtEJDkovCTp7L+/L+u66y6YObOYE44/Hk480SvPz5iR8PaJSPQUXpKUhg717VN+t+tygfvvh2rVtPeXSAWl8JKk1KiR7/f15pt+/M4uu8Djj/ueKjfckPD2iUi0FF6StC69FPbYw3tf69YVc0Lv3r4x2N//Du++m/D2iUh0FF6StKpW9dHBmTPhnntKOOnuu7221FlnwYIFCW2fiERH4SVJ7cgjoVcvX/9VbGH5rCwYPRqWLYOBAxPePhGJhsJLkt5dd/n6r2uvLeGEdu3gwgvhqad8cZiIpD2FlyS9li3h6qu9OtRHH5Vw0sCBXlvqxhsT2jYRiYbCS1LCwIHQtKnXPdy0qZgTGjSAK66Af/3LK2+ISFpTeElKqF7dK85PmgSPPVbCSVdcAXXrwqBBCW2biCSewktSxkknwYEH+rKu5cuLOaF2be+ivf02jBuX8PaJSOIovCRlmMG998Kvv/rsw2JddBE0aeLV51V5QyRtKbwkpXTuDP36wX33lVDWMCvLt2WeOhVuvz3h7RORxFB4ScoZMsTLGl51VQkn/PGPvuPykCEeYiKSdhReknJ23tnnZLz+Orz3Xgkn3Xuv3wM799wSpieKSCpTeElKGjDA138NGAAbNhRzQoMG8MAD8Pnn8Ne/Jrx9IlK+FF6SkqpV87KG06fDiBElnHTKKXDGGb7v15AhCW2fiJQvhZekrOOPhyOOgJtugkWLijnBDJ58Es48EwYP9hNDSHg7RST+FF6Sssx81uGqVZ5NxcrI8ADr3x9uvVU9MJE0ofCSlNamjS/pevRR+PLLEk6qXNlPOPNMr334wQcJbaOIxJ8FDaMkRG5ubsjLy4u6GWlp2TJo3RpatfLCvWYlnLh6NeTmenmOr77ySR0iktTMbEIIIXfLx9XzkpSXkwNDh8L48fD001s5sUYNeP55WLLEVzrrH24iKUvhJWnhnHOgSxffOmXFiq2c2LGjV/h9802/YSYiKUnhJWmhUiV48EFYuNBnxm/VRRdBz56edJ98kpD2iUh8KbwkbeTmwnnneYdq2rStnGgG//gHNGvmpeqLnWcvIslM4SVpZcgQqFULLr+8lFtaOTnw0kuweDH07asSUiIpRuElaaV+fV+LPHYsjBlTysl77w3Dh8P77/uLRCRlaKp8gmiqfOJs2ADt2/t9sMmToUqVUl7Qv78PI44b57tdikjS0FR5qTCqVPEJhd98AyNHluEF998Pu+4KZ51VylRFEUkWCi9JS8ceC4cd5qOBS5eWcnLNmjBqFMye7TfLRCTpKbwkLZl51fmlS8swdR7ggAPguuvgiSfg1VfLvX0ismMUXpK2OnaE88/3bb0mTSrDC266CTp18g0sZ80q9/aJyPZTeEla+9vfoF49uPBCyM8v5eSqVeGFF3yOfc+esHJlQtooIttO4SVprU4dn7zxySfw+ONleMHuu3uAff21V6EvNfFEJAoKL0l7Z54JBx8M115bxmIahx/uN8xee823UBGRpKPwkrRnBg895KOAV19dxhddconf+xoyBN59t1zbJyLbTuElFULbth5cTz1Vxr0ozXymR7t2cPbZqn8okmQUXlJh3HAD7Labz0Bcs6YML8jKgmef9fn2/ftr/y+RJLLV8DKz/5rZUVs8dpmZPVTK61bF/tzFzF7cyrV/V/KjmPeqXuT3t8wsZ2uvKQszu9nMrtrR60hqycqChx+GmTN9NLBMOnSAYcPg3/+GESPKtX0iUnal9byeA07d4rFTY4+XKoQwN4TQZ3saFnMZ8P/hFUI4JoSwbAeuJxXc4Yd7Fahhw2Dq1DK+6NJLoUcPuOIKeOedcm2fiJRNaeH1InCsmWUCmFkLYBfgIzOraWbvm9lEM5tiZj23fLGZtTCzqbGfs8zseTObbGajgawi540wszwzm2Zmt8QeuzT2Xv8xs//EHvvRzOrHfr7CzKbGjsuKvN/XZvZo7FrvmlkWZVTCNWuY2Ztm9lXs8VNijw81s+mxz3NnWd9DonfXXVC7tu/9VaadUMzg6aehTRs4/nh4661yb6OIbN1WwyuEsBj4HOgRe+hUYHTwUvRrgRNCCJ2BQ4G7zMy2crm/AL+FEDoAQ4B9ijw3KFY1uANwsJl1CCHcD8wFDg0hHFr0Qma2D9AP6AJ0Bc4zs06xp1sBw0MI7YBlwIlb/S9Q+jV7AHNDCB1DCO2Bt82sLnAC0C72eW4r4Zp/joVy3iLd8E8a9et7Ld5PP4V77y3ji+rV861T2reHXr3gjTfKtY0isnVlmbBRdOiw6JChAX8zs8nAe0BjoOFWrnMQ8DRACGEyMLnIcyeb2UTgS6Ad0LaUNnUHXgkhrA4hrAJeBgr2svghhFBQDGgC0KKUa5V2zSnA4WY2zMwODCEsB1bg4f2YmfUGfivugiGER0IIuSGE3AYNGpSxGZIIfft6EY3Bg+Hbb8v4orp14b33fB+w3r3hX/8q1zaKSMnKEl6vAn8ws85AVghhYuzx04EGwD4hhL2BBUC1Uq71u+laZrYrcBXwh1gv5s0yXGdrPbx1RX7eBGSUcq2tXjOE8B3eS5wC3G5mN4YQNgL7AS8BvYC3y/gekiTMfP5FVhb067cNGynXqeM7XXbpAqeeCk8+Wa7tFJHilRpesV7If4En2HyiRm1gYQhhg5kdCjQv5VIf4oGHmbXHhwgBagGrgeVm1hA4ushrVgLZJVyrl5lVN7Ma+BDe/0r7LGVo3++uaWa74MOdTwN3Ap3NrCZQO4TwFj6pZO8dfG+JQKNGvpTrk0+2YfgQ/IbZO+/47I/+/f0iIpJQZe2VPIcPoxWdefgM8IaZ5QGTgG9KucYI4MnYMOMk/F4aIYSvzOxLYBowC/i4yGseAcaY2byi971CCBPN7B8F1wAeCyF8GZtQUlaDCyZlxK7ZpIRrHgXcYWb5wAb83l028JqZVcN7bNoEKkWddpqXMhw82PcA22OPMr6wRg14/XUff7z0Uli4EG691bt0IlLuLGjhZULk5uaGvLy8qJshxZg3zwtptGkDH34IlStvw4s3boS//AUee8wrcTz6qG/lLCJxYWYTYhP6NqMKG1LhNWrksw/Hj/c/t0lGBjzyiO94+dRT3n1bvbpc2ikihRReIsDpp8Nxx8H118N3323ji828+vzjj/tkjgsuUCkpkXKm8BLB82fkSKhWzWcfbty4HRfp3997YE8/7RcTkXKj8BKJadQIhg/34cPbb9/OiwwaBEcfDQMGwBdfxLV9IlJI4SVSxGmn+RDiLbf4FPptVqkSjBoFO+8MffrADz/EvY0iovAS+Z3hw6FpUw+xFSu24wL16sGLL8Kvv/rc+0svhQUL4t5OkYpM4SWyhdq1/bbVTz/BRRdt59yLfff1mR/9+vk2zrvt5ouZNZFDJC4UXiLF6NbNJxA+/bQv4doujRv7xI3p0+Hgg70HduyxvqBZRHaIwkukBIMHw5FHwsUX7+Dci9atfTPLBx/0yvQdOvhqaBHZbgovkRJUrgzPPuuzEE880W9hbTczH4PMy4OcHDjqKHj33bi1VaSiUXiJbEW9evDSSz7S17fvNlSfL0n79vC///lEjuOO075gIttJ4SVSin328TkX773ny7h2WIMG8MEH0LGj7wv2/PNxuKhIxaLwEimD/v296tOwYXHag7JgY8v99/cu3Z13aiaiyDZQeImU0X33edb06wdTp8bhgrVq+X2vk0+Gq6+GSy6Jw7ikSMWg8BIpo6pVfe1xdjaccAIsWRKHi1arBs895+E1fLhPqf/sszhcWCS9KbxEtsEuu3iAzZ7tAbZuXRwuWqkS/P3vvqXKzJnQtSuccgr8+GMcLi6SnhReItuoWzfPmQ8/9CHE/Pw4Xfiss2DGDF8d/e9/Q+fOWg8mUgKFl8h2OPVUrzz/3HO+mDlusrO9KvCUKdCwIRx+uJf5EJHNZETdAJFUde21XjT+9tt9IfMll8Tx4i1b+t4svXvDmWf61Pojj/QZI82a+aJnkQpMPS+R7WTmcyx69fKyhXHvINWpA++843P0R4/2KfUtWvhC59de09R6qdAUXiI7ICPDhw4PPRTOOaccCmZUrQojRsCyZTBhglemz8/3xDzkEG14KRWWwktkB1Wr5h2hzp3hpJN87XHcVanib3DxxX4/bMQI+OYbn5n4179qfZhUOAovkTjIzoa33vIC8scdB2PHluObZWT4UOKMGT6UeOONfj9s3rxyfFOR5KLwEomT+vV9XkXr1nD88QkoGl+rFowaBU88AZ98Arvv7rMTb77ZJ3uIpDGFl0gc1a/vW3btsYcH2Jgx5fyGZr7YbMIEL8C4eLEPI3br5gufRdKUwkskzgoCrF076NkzToV8S9OmjU/m+PJLr1t16qk+l/+mmzQrUdKS1nmJlIN69XwI8Y9/9BxZtco7SAlRu7bP28/KgltvhZUrfTFaZmaCGiBS/tTzEikntWv7Mq3DD/cRvZtvTuCkwMqV4bHHfPfme+7xhc033ABz5iSoASLlS+ElUo5q1IDXX/eyhbfckuBJgZUq+VDiu+9Cly4wZAg0aQKNG8OBB3qifvxxghojEl8KL5FylpnphXyffNInBe69t98TSwgzOOIIT9AZMzzAjjrKe2avvgrdu0OPHvD55wlqkEh8WNDN3ITIzc0NeXl5UTdDIjZ9OvTpA99+C0OHwlVXRVimcPVqeOgh3x568WKf43/44fCHP8DRR/s9M5GImdmEEELulo+r5yWSQG3b+l6TvXvDNdf4JsorV0bUmBo1fBPMH36A++/3dWJPPQUnnug1FIcNgxUrImqcyNYpvEQSLDsbXnjBl2G9/DLsu69XfIq0QZdcAm++CUuXenmQvfeG666D5s3h/PO9ocuXR9hIkc0pvEQiYOadnvfe80zYbz+fHBj5KH6VKj50+M47fh/syCO98vCJJ/r8/4MO8h7Z1KlJ0FipyBReIhE69FCYNMnnTZx3npcqXLo06lbF7Luvb8WyeLHv6Hzddb5g7brrYK+9fJhx4EBfGK0gkwRTeIlErGFDePttnwj40kueC+Va2HdbVaniU+tvuw0mToRffoFHHoFWreCOO7zaffv2Xul+1aqoWysVhGYbJohmG0pZTJjgGyd//TVceKHPSMzOjrpVW7F4sd8PGznSG1+7NpxwgodZmzZeI0s7P8sOKGm2ocIrQRReUlZr1sD118N990HTpt7JOeqoqFtVihDg0099UfT778PChYXP1aoFHTr4MGSfPr4HWSUN+kjZKLwipvCSbTV+PJx7ru85edppXp6wWbOoW1VGixd793HqVJ9K+dVXkJcH69b5hzjsMN8det48WL/eC0Cee65PChEpQuEVMYWXbI+1a/1e2B13+O+XX+7zJWrXjrZd22XFCt9yevRoD7IGDaBRI18sPX68lyI56SSf4XjAAdCypYYbReEVNYWX7IiffoLBg71YfL16PsnvwgvTqAjG1Kle7ePZZwvXkzVs6Ku5zzzThxoVZBWSwitiCi+Jh4kTPbjefdfr6954I5xzDlStGnXL4mTTJq+hNX683zt74w3vfjZv7j21jRv9/tr++3t5koMO8jqNkrYUXhFTeEk8/fe/HmKffup/rw8aBGefnUYhVmDFCnjlFS8ivG4dZGTAhg2+7uy332CnnbxX1qrV5kfjxpoUkiYUXhFTeEm8heDrw265xeslNmsGAwb4vIeUvCe2LX77Dd56yxfGTZkCM2d6uBXIyoLddis8Gjb0x7KyfFuYAw7wWZAF5s/3YcmGDRP/WWSrFF4RU3hJeQnBqzkNHQrjxvm6sD/9yYOsefOoW5cg+fm+eHrGjMJj5kz4/ns/1q7d/PxKlaBTJ++5TZrksx6rVvWNO//yF91fSyIKr4gpvCQR8vL879/Ro/33k0+GK6+EffaJtl2Rys/3ntratb6I7rvvfNhx3DivxdWxowfZ2LEwZoxP2x850gPts89g0SIfk61fP+pPUiEpvCKm8JJEmj3bdzl55BHfcqVrV7jgAg+ztJmhGG/5+V50ePBg73lt2lT4XHa2/yvgiiugZk0PwZUrPRDXrvWJJM2aJXk5lNSk8IqYwkuisHy57+D88MO+AWZODpxxBvTv750NKcaHH/okkb32gi5dfFz25pv9/lpmpofaxo3Fv7ZRIy9YvGYNLFjgi7WPPNJvTHbo8PvzN270EKxe3a8tv6PwipjCS6IUgo+SjRzpfy+vW+ejZX37+m4nu+8edQtTQF6er0PLzPQZMbVqeTc2M9Pvof34o/8L4fvvfaPPgkkizz7rsyZPPtlvQk6f7tVHFizwBdrgr2/RAvbYw/dSO/xw6NZNgYbCK3IKL0kWS5f6Fl1PPeVbdoEH2cknwymn+OQ8iaOlS+Guu7xY5fr1sOeeXrS4cWMPwexsL5X17bd+TJnivbusLO/5dejgR6tW3nXOyfGV6jVqbP0958zxMKxSJXGftRwovCKm8JJk9NNPXhT+xRd9XTD45I7evaFnT2jbVhPv4mbdOl9QnZGx9fNWrPBu8tixPmFk6lSfcLKlnXaCXXf1EAzBA2/VKu/VzZvn59Sq5XUkjzzSCyO3a5dyNz0VXhFTeEmymz0b/vUveOGFwh5Zy5Zw7LFwzDFw8MFQrVq0bayQ8vNh1iz44Qe/ibl8uVft/+EHP+bN839hVK7swdS6tYfUzjvDRx/5OorZs/1alSp5D27PPf3PXXf14cvp070CdH6+B16tWt5r69bNd0pt3Diyj6/wipjCS1LJ3Llemen11+GDD3xCXVYW9OoFF1/s1ZnUI0sRIXj4ffWVH1Om+HKBgoXdlSr5WHGbNj7EuGKFD2NOm1bY4+vc2b/4U0/1nuNbb/m48/z5PrGlQwe/Z1e5sl+vdm3f021rQ5tlpPCKmMJLUtWaNV6O6o034Jln/O+2zp3h9NP9H+WdOqX8bZWKadMmD5969YrvUm/Y4GE3bpxPWZ02zc+tXNl7fjvv7L28KVP8HtuWKlXyHl7nzr7PW07OdjVT4RUxhZekg1WrvLL98OF+Kwa8R9a1qw8rHnSQ/5xit1WkNCH4v2AeftiHFs8+G3r08F5YCD45ZM4c/zk/3xd2f/ml7679zTd+bGcBZYVXxBRekm7mzoWPP/bbKh9+6P9ID8H/PuvY0SfKdeniE0D23FPF32X7KLwipvCSdLdsmQfZ+PFe7f6LL7ynBr4Gt2NHH0Hq1MmPtm01AURKp/CKmMJLKppNm3zZ0oQJfkyc6DVwV6705wsmvnXo4MFWcDRposkgUkjhFTGFl0jhrO9Jk/w+/+TJfsyaVXhOdrZPfGvb1md8FxxNmmiLropI4RUxhZdIyVasKAyz6dMLj/nzC8/JzPRlSS1bejmrVq38z5YtveqSKimlp5LCq5Sl3iIi5a9WLV8P263b5o8vWeIztKdPL9ya6/vvffZ2QVlA8GHGXXbxcPMvKbkAAAmfSURBVGve3JccNW/uhd6bN4emTeOy5EiSiHpeCaKel0j8hOC9shkzvMjEjz8W/vnTT/Dzz5vvaAK+k0mjRj782KyZH02bevGIgqNuXQ1NJhv1vEQkbZh5EDVq5GvLtrRxo0/lnz3bw2zOHK+iNG+eb7j8wQf+WH7+5q/LyPCSgTvv7NfeeWfv0RUcjRp5sfiGDTVMGTWFl4iknYyMwt5V9+7Fn1MQcAXra+fO9TJ/8+d7yM2d67MkFy78fciBF4zYaSc/GjTwXltODtSp478XPLfTTh52NWtqFmU8KbxEpEIqGnBbs2mTB9jcuZsH3IIFXkhi4UIvFbh0qR9r1hR/nawsr65UsKtJnTp+1K1b+HPR3wvCsHZtrYcrjsJLRGQrKlcuHKLcZ5/Sz1+7Fn791UNtwYLCPxcs8HBbtsyPn3/22ZVLlhSufStJ1aoeZHXrFoZbwX6YtWr5zwW/16zpR3Z2YVDm5PgwZzr1/BReIiJxVK2aTwpp0qTsr9mwwQOtoPe2ZIkfS5f6MoKCQu8Fj8+d6wvAC3ZIWb++9PeoUsXDLTvbZ14WHEXDLzt78/ArOKpX98+VmemvKQjKKAsyK7xERCJWpYrfJ2vQYPtev26dB9zy5V6Sa9Wqwt8LQnHlysIg/O03X2qwevXm24StXPn7WZpbk5npoZaV5UeNGh501at7b7HgeOaZ+A99KrxERFJcZuaOhV+BELwXt3JlYQCuWOH38dau9WP16sLHV63y5wqOgkBcs8afX7/ej/JYfqDwEhERwO+JZWb6Ub9+1K3ZOi3HExGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlKPwEhGRlLPD4WVm9cxsUuyYb2ZzivxetYzXeNLM9ijlnIvM7PQdbW/sWh+Z2d7xuJaIiCTeDhfmDSEsBvYGMLObgVUhhDuLnmNmBlgIoZjNtCGE0K8M7zN8R9sqIiLpodyGDc1sdzObamYPAxOBRmb2iJnlmdk0M7uxyLkfmdneZpZhZsvMbKiZfWVmn5jZTrFzbjOzy4qcP9TMPjezb83sgNjjNczspdhrn4u9V5l6WGaWZWZPmdkUM5toZgfFHt/LzL6I9SQnm1lLM8s2szGx95lqZn3i/d9PRERKVt73vNoCj4cQOoUQ5gDXhRBygY7AEWbWtpjX1AbGhRA6Ap8A/Uu4toUQ9gOuBgqC8BJgfuy1Q4FO29DWS4H1IYS9gDOBUbFhzwuBO0MIewP7AnOBY4AfQwgdQwjtgbHFNtDsz7EAzVu0aNE2NEVERLamvMPr+xDCF0V+72tmE/GeWBs83La0JoQwJvbzBKBFCdd+uZhzugPPA4QQvgKmbUNbuwOjYq+dhofU7sB4YLCZXQM0DSGsBSYDPWK9v24hhOXFXTCE8EgIITeEkNtgR3eJExGR/1fe4bW64AczawUMAA4LIXQA3gaK2xh6fZGfN1Hyfbl1xZxjO9DWYl8bQhgFnBB7v7FmdlAI4WsgFw/HO8zs+h14XxER2UaJnCpfC1gJrDCzRsBR5fAeHwEng9+rovieXUk+BE6PvbYN0AiYaWYtQwgzQwj3AW8CHcysMT4xZRRwN9A5jp9BRERKscOzDbfBRGA6MBWYBXxcDu/xAPBPM5sce7+pQLFDesA7ZrYh9vP/8HtrI81sCrABOCuEsN7MTjOzvrHH5gKDgQOAoWaWj/cULyiHzyIiIiWwEELUbYgbM8sAMkIIa2PDlO8CrUIIGyNuGrm5uSEvLy/qZoiIpBQzmxCb6LeZRPa8EqEm8H4sxAw4PxmCS0RE4iutwiuEsAzYJ+p2iIhI+VJtQxERSTkKLxERSTlpNWEjmZnZIuCn7Xx5feDXODYnFVTEzwwV83NXxM8MFfNzb89nbh5C+F2VB4VXCjCzvOJm26SziviZoWJ+7or4maFifu54fmYNG4qISMpReImISMpReKWGR6JuQAQq4meGivm5K+Jnhor5ueP2mXXPS0REUo56XiIiknIUXiIiknIUXknMzHqY2bdmNtPMrou6PeXFzJqa2X/M7Gszm2ZmA2KP1zWzsWY2I/ZnnajbGm9mVtnMvjSzf8d+39XMPot95tGx3bzTipnlmNmLZvZN7DvfP92/azO7PPb/9lQze87MqqXjd21mT5jZQjObWuSxYr9bc/fH/n6bbGbbtLWUwitJmVllYDhwNL4vWV8z25b9yVLJRuDKEEIboCtwUeyzXge8H0JoBbwf+z3dDAC+LvL7MOCe2GdeCpwbSavK133A2yGEPYGO+OdP2+86tv/fpUBuCKE9UBk4lfT8rv8B9NjisZK+26OBVrHjz8CIbXkjhVfy2g+YGUKYFUJYDzwP9Iy4TeUihDAvhDAx9vNK/C+zxvjnfSp22lNAr2haWD7MrAnwR+Cx2O8GHAa8GDslHT9zLeAg4HGAEML6WEHttP6u8SLoWbEdL6oD80jD7zqE8CGwZIuHS/puewL/DO5TICe2UXGZKLySV2Pg5yK//xJ7LK2ZWQugE/AZ0DCEMA884ICdomtZubgXuAbIj/1eD1hWZBufdPzOWwKLgCdjw6WPmVkN0vi7DiHMAe4EZuOhtRyYQPp/1wVK+m536O84hVfysmIeS+t1DWZWE3gJuCyEsCLq9pQnMzsWWBhCmFD04WJOTbfvPAPoDIwIIXQCVpNGQ4TFid3j6QnsCuwC1MCHzLaUbt91aXbo/3eFV/L6BWha5PcmwNyI2lLuzKwKHlzPhBBejj28oGAYIfbnwqjaVw66Aceb2Y/4kPBheE8sJza0BOn5nf8C/BJC+Cz2+4t4mKXzd3048EMIYVEIYQPwMnAA6f9dFyjpu92hv+MUXsnrC6BVbEZSVfwG7+sRt6lcxO71PA58HUK4u8hTrwNnx34+G3gt0W0rLyGEgSGEJiGEFvh3+0EI4XTgP0Cf2Glp9ZkBQgjzgZ/NbI/YQ38AppPG3zU+XNjVzKrH/l8v+Mxp/V0XUdJ3+zpwVmzWYVdgecHwYlmowkYSM7Nj8H+NVwaeCCEMibhJ5cLMugP/A6ZQeP/nevy+1wtAM/wvgJNCCFveDE55ZnYIcFUI4Vgza4n3xOoCXwJnhBDWRdm+eDOzvfFJKlWBWUA//B/Saftdm9ktwCn4zNovgT/h93fS6rs2s+eAQ/CtTxYANwGvUsx3GwvyB/HZib8B/UIIeWV+L4WXiIikGg0biohIylF4iYhIylF4iYhIylF4iYhIylF4iYhIylF4iYhIylF4iYhIyvk/fk8f1DNEl34AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = keras.models.load_model(\"digitizer_95.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.9787358e-01 5.0761952e-04 9.8371260e-02 2.8241673e-01 1.5102203e-03\n",
      "  1.9428970e-01 5.8493722e-04 5.2069989e-04 2.3714721e-02 2.1057106e-04]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('sudo_2.jpg', 0)/255\n",
    "delta = int(img.shape[0]/9)\n",
    "crop = img[5:delta, 5:delta]\n",
    "y_pred = model.predict(preprocess(crop))\n",
    "print(y_pred)\n",
    "print(np.where(y_proba == np.amax(y_proba))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ww\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = []\n",
    "\n",
    "if arr:\n",
    "    print('hi')\n",
    "else:\n",
    "    print('ww')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
